---
apiVersion: helm.toolkit.fluxcd.io/v2
kind: HelmRelease
metadata:
  name: &app ollama
  namespace: ai
spec:
  interval: 30m
  chart:
    spec:
      chart: ollama
      sourceRef:
        kind: HelmRepository
        name: ollama
        namespace: flux-system

  maxHistory: 2

  install:
    remediation:
      retries: 3

  upgrade:
    cleanupOnFail: true
    remediation:
      retries: 3

  uninstall:
    keepHistory: false

  values:
    replicaCount: 1
    image:
      repository: docker.io/ollama/ollama
      tag: "0.1.45"  # Leave it empty to use the chart's default version
    ollama:
      gpu:
        # Enable GPU integration
        enabled: true
        # Specify the number of GPU
        number: 1
        # Default model to serve, if not set, no model will be served at container startup
      defaultModel: "codellama"

      serviceAccount:
        # Specifies whether a service account should be created
        create: true
        # Automatically mount a ServiceAccount's API credentials?
        automount: true
        # The name of the service account to use.
        # If not set and create is true, a name is generated using the fullname template
        name: ""

      runtimeClassName: nvidia

    service:
      main:
        ports:
          http:
            port: 11434

    ingress:
      main:
        enabled: true
        className: internal
        hosts:
          - host: &host ollama.${SECRET_DOMAIN}
            paths:
              - path: /
                service:
                  name: main
                  port: http

    resources:
      requests:
        memory: 4096Mi
        cpu: 2000m
        nvidia.com/gpu: 1
      limits:
        memory: 24Gi
        cpu: 4000m
        nvidia.com/gpu: 1

    livenessProbe:
      enabled: true
      path: /
      initialDelaySeconds: 60
      periodSeconds: 10
      timeoutSeconds: 5
      failureThreshold: 6
      successThreshold: 1
    readinessProbe:
      enabled: true
      path: /
      initialDelaySeconds: 30
      periodSeconds: 5
      timeoutSeconds: 3
      failureThreshold: 6
      successThreshold: 1

    persistentVolume:
      enabled: true
      size: 40Gi
      storageClass: ceph-block
      accessModes:
        - ReadWriteOnce

    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
            - matchExpressions:
                - key: nvidia.com/gpu.present
                  operator: In
                  values:
                    - "true"

    nodeSelector:
      nvidia.com/gpu.present: "true"
